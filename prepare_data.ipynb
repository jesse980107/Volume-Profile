{
 "cells": [
  {
   "cell_type": "code",
   "source": "# 保存为项目所需格式：300809.sz.csv\n# 注意：文件名使用小写 sz\n\n# 提取股票代码的数字和后缀部分\ncode_number = TS_CODE.split('.')[0]  # '300809'\ncode_suffix = TS_CODE.split('.')[1].lower()  # 'sz'\n\n# 构建文件名\noutput_filename = f'data/{code_number}.{code_suffix}.csv'\n\n# 保存合并后的数据\ndf_merged.to_csv(output_filename, index=False, encoding='utf-8-sig')\n\nprint(\"=\"*60)\nprint(f\"✅ 项目格式数据已保存: {output_filename}\")\nprint(f\"   文件大小: {os.path.getsize(output_filename) / 1024:.2f} KB\")\nprint(f\"   记录数: {len(df_merged)}\")\nprint(f\"   日期范围: {df_merged['trade_date'].min()} ~ {df_merged['trade_date'].max()}\")\nprint(\"=\"*60)\nprint(\"\\n🎉 现在可以在项目中使用该股票数据了！\")\nprint(f\"   股票代码: {TS_CODE}\")\nprint(f\"   数据文件: {output_filename}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. 保存为项目所需格式（300809.sz.csv）",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000155 股票数据预处理\n",
    "\n",
    "本 Notebook 用于从 Tushare 拉取 000155（中联重科）的**全部历史日线数据**和 **daily_basic 数据**，并保存到本地文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入依赖包\n",
    "\n",
    "```bash\n",
    "pip install tushare pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(f\"tushare version: {ts.__version__}\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置 Tushare Token\n",
    "\n",
    "**请替换为你的 Tushare Pro Token**\n",
    "\n",
    "获取方式：https://tushare.pro/register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ⚠️ 请替换为你的 Token\nTOKEN = 'your_tushare_token_here'\n\n# 初始化 Tushare Pro API\npro = ts.pro_api(TOKEN)\n\n# 股票代码\nTS_CODE = '000155.SZ'  # 中联重科\n\n# 使用通用的早期日期，无需手动查找上市日期\n# 1990-01-01 早于所有A股上市日期，API会自动从实际上市日开始返回数据\nSTART_DATE = '19900101'\n\nprint(f\"股票代码: {TS_CODE}\")\nprint(f\"查询起始日期: {START_DATE}（实际从上市日开始）\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义数据获取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_daily_data(ts_code, start_date, sleep_time=0.3):\n",
    "    \"\"\"\n",
    "    分批获取全部历史日线数据\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ts_code : str\n",
    "        股票代码，如 '000155.SZ'\n",
    "    start_date : str\n",
    "        开始日期，格式 'YYYYMMDD'\n",
    "    sleep_time : float\n",
    "        每次请求间隔时间（秒），避免请求过快\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        包含全部历史日线数据的 DataFrame\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # 计算日期范围\n",
    "    start = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end = datetime.now()\n",
    "    \n",
    "    current_start = start\n",
    "    \n",
    "    print(f\"开始获取日线数据: {start_date} ~ {end.strftime('%Y%m%d')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    batch_count = 0\n",
    "    \n",
    "    # 每次获取1年的数据\n",
    "    while current_start < end:\n",
    "        current_end = min(current_start + timedelta(days=365), end)\n",
    "        \n",
    "        start_str = current_start.strftime('%Y%m%d')\n",
    "        end_str = current_end.strftime('%Y%m%d')\n",
    "        \n",
    "        try:\n",
    "            df = pro.daily(\n",
    "                ts_code=ts_code,\n",
    "                start_date=start_str,\n",
    "                end_date=end_str\n",
    "            )\n",
    "            \n",
    "            if not df.empty:\n",
    "                all_data.append(df)\n",
    "                batch_count += 1\n",
    "                print(f\"[{batch_count:2d}] {start_str} ~ {end_str}: {len(df):4d} 条\")\n",
    "            else:\n",
    "                print(f\"[{batch_count:2d}] {start_str} ~ {end_str}: 无数据\")\n",
    "            \n",
    "            time.sleep(sleep_time)  # 避免请求过快\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 获取数据失败 [{start_str} ~ {end_str}]: {e}\")\n",
    "        \n",
    "        current_start = current_end + timedelta(days=1)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 合并所有数据\n",
    "    if all_data:\n",
    "        result = pd.concat(all_data, ignore_index=True)\n",
    "        # 去重并排序\n",
    "        result = result.drop_duplicates(subset=['trade_date']).sort_values('trade_date')\n",
    "        print(f\"✅ 日线数据获取完成，共 {len(result)} 条记录\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"❌ 未获取到任何数据\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_all_daily_basic(ts_code, start_date, sleep_time=0.3):\n    \"\"\"\n    分批获取全部历史 daily_basic 数据（包含流通股本等指标）\n    \n    Parameters:\n    -----------\n    ts_code : str\n        股票代码，如 '000155.SZ'\n    start_date : str\n        开始日期，格式 'YYYYMMDD'\n    sleep_time : float\n        每次请求间隔时间（秒）\n    \n    Returns:\n    --------\n    pd.DataFrame\n        包含全部历史 daily_basic 数据的 DataFrame\n    \"\"\"\n    all_data = []\n    \n    start = datetime.strptime(start_date, '%Y%m%d')\n    end = datetime.now()\n    \n    current_start = start\n    \n    print(f\"开始获取 daily_basic 数据: {start_date} ~ {end.strftime('%Y%m%d')}\")\n    print(\"=\" * 60)\n    \n    batch_count = 0\n    \n    while current_start < end:\n        current_end = min(current_start + timedelta(days=365), end)\n        \n        start_str = current_start.strftime('%Y%m%d')\n        end_str = current_end.strftime('%Y%m%d')\n        \n        try:\n            df = pro.daily_basic(\n                ts_code=ts_code,\n                start_date=start_str,\n                end_date=end_str,\n                # 注意：移除了 close 字段，因为 daily 接口已经提供了\n                fields='ts_code,trade_date,turnover_rate,turnover_rate_f,volume_ratio,pe,pe_ttm,pb,ps,ps_ttm,dv_ratio,dv_ttm,total_share,float_share,free_share,total_mv,circ_mv'\n            )\n            \n            if not df.empty:\n                all_data.append(df)\n                batch_count += 1\n                print(f\"[{batch_count:2d}] {start_str} ~ {end_str}: {len(df):4d} 条\")\n            else:\n                print(f\"[{batch_count:2d}] {start_str} ~ {end_str}: 无数据\")\n            \n            time.sleep(sleep_time)\n            \n        except Exception as e:\n            print(f\"❌ 获取数据失败 [{start_str} ~ {end_str}]: {e}\")\n        \n        current_start = current_end + timedelta(days=1)\n    \n    print(\"=\" * 60)\n    \n    if all_data:\n        result = pd.concat(all_data, ignore_index=True)\n        result = result.drop_duplicates(subset=['trade_date']).sort_values('trade_date')\n        print(f\"✅ daily_basic 数据获取完成，共 {len(result)} 条记录\")\n        return result\n    else:\n        print(\"❌ 未获取到任何数据\")\n        return pd.DataFrame()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 获取日线数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 获取全部历史日线数据\ndf_daily = get_all_daily_data(TS_CODE, START_DATE, sleep_time=0.3)\n\n# 查看数据\nprint(\"\\n数据预览:\")\ndisplay(df_daily.head())\nprint(\"\\n数据信息:\")\nprint(df_daily.info())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 获取 daily_basic 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 获取全部历史 daily_basic 数据\ndf_basic = get_all_daily_basic(TS_CODE, START_DATE, sleep_time=0.3)\n\n# 查看数据\nprint(\"\\n数据预览:\")\ndisplay(df_basic.head())\nprint(\"\\n数据信息:\")\nprint(df_basic.info())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并日线数据和 basic 数据\n",
    "df_merged = pd.merge(\n",
    "    df_daily, \n",
    "    df_basic, \n",
    "    on=['ts_code', 'trade_date'], \n",
    "    how='left',\n",
    "    suffixes=('', '_basic')\n",
    ")\n",
    "\n",
    "print(f\"✅ 数据合并完成\")\n",
    "print(f\"   - 日线数据: {len(df_daily)} 条\")\n",
    "print(f\"   - basic数据: {len(df_basic)} 条\")\n",
    "print(f\"   - 合并后: {len(df_merged)} 条\")\n",
    "\n",
    "# 查看合并后的数据\n",
    "print(\"\\n合并后数据预览:\")\n",
    "display(df_merged.head())\n",
    "\n",
    "# 查看列名\n",
    "print(\"\\n列名:\")\n",
    "print(df_merged.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 数据质量检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"数据质量检查报告\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 基本统计\n",
    "print(f\"\\n1. 基本信息\")\n",
    "print(f\"   股票代码: {TS_CODE}\")\n",
    "print(f\"   数据起始: {df_merged['trade_date'].min()}\")\n",
    "print(f\"   数据终止: {df_merged['trade_date'].max()}\")\n",
    "print(f\"   总记录数: {len(df_merged)}\")\n",
    "\n",
    "# 缺失值检查\n",
    "print(f\"\\n2. 缺失值统计\")\n",
    "missing = df_merged.isnull().sum()\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "if len(missing) > 0:\n",
    "    print(missing)\n",
    "else:\n",
    "    print(\"   ✅ 无缺失值\")\n",
    "\n",
    "# 重复值检查\n",
    "print(f\"\\n3. 重复值检查\")\n",
    "duplicates = df_merged.duplicated(subset=['trade_date']).sum()\n",
    "print(f\"   重复日期数: {duplicates}\")\n",
    "\n",
    "# 数据范围\n",
    "print(f\"\\n4. 价格数据统计\")\n",
    "print(f\"   最高价: {df_merged['high'].max():.2f}\")\n",
    "print(f\"   最低价: {df_merged['low'].min():.2f}\")\n",
    "print(f\"   平均收盘价: {df_merged['close'].mean():.2f}\")\n",
    "\n",
    "# 成交量统计\n",
    "print(f\"\\n5. 成交量统计\")\n",
    "print(f\"   平均成交量: {df_merged['vol'].mean()/10000:.2f} 万手\")\n",
    "print(f\"   最大成交量: {df_merged['vol'].max()/10000:.2f} 万手\")\n",
    "\n",
    "# 股本统计（如果有）\n",
    "if 'total_share' in df_merged.columns:\n",
    "    print(f\"\\n6. 股本统计（最新）\")\n",
    "    latest = df_merged.iloc[-1]\n",
    "    print(f\"   总股本: {latest['total_share']:.2f} 万股\")\n",
    "    if pd.notna(latest.get('float_share')):\n",
    "        print(f\"   流通股本: {latest['float_share']:.2f} 万股\")\n",
    "    if pd.notna(latest.get('free_share')):\n",
    "        print(f\"   自由流通股本: {latest['free_share']:.2f} 万股\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存数据到本地\n",
    "\n",
    "将数据保存为多种格式，方便后续使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 data 目录（如果不存在）\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# 文件路径\n",
    "csv_path = f'data/{TS_CODE.replace(\".\", \"_\")}_full_history.csv'\n",
    "csv_daily_path = f'data/{TS_CODE.replace(\".\", \"_\")}_daily.csv'\n",
    "csv_basic_path = f'data/{TS_CODE.replace(\".\", \"_\")}_basic.csv'\n",
    "\n",
    "# 保存合并数据\n",
    "print(\"开始保存数据...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. 保存合并后的完整数据\n",
    "df_merged.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ 合并数据已保存: {csv_path}\")\n",
    "print(f\"   文件大小: {os.path.getsize(csv_path) / 1024:.2f} KB\")\n",
    "\n",
    "# 2. 分别保存日线和 basic 数据\n",
    "df_daily.to_csv(csv_daily_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n✅ 日线数据已保存: {csv_daily_path}\")\n",
    "print(f\"   文件大小: {os.path.getsize(csv_daily_path) / 1024:.2f} KB\")\n",
    "\n",
    "df_basic.to_csv(csv_basic_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n✅ Basic数据已保存: {csv_basic_path}\")\n",
    "print(f\"   文件大小: {os.path.getsize(csv_basic_path) / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 所有数据保存完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 测试读取保存的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试读取保存的数据\n",
    "test_df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"✅ 数据读取成功！\")\n",
    "print(f\"   记录数: {len(test_df)}\")\n",
    "print(f\"   列数: {len(test_df.columns)}\")\n",
    "print(\"\\n前5条记录:\")\n",
    "display(test_df.head())\n",
    "print(\"\\n后5条记录:\")\n",
    "display(test_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 数据说明\n",
    "\n",
    "### 保存的文件\n",
    "\n",
    "1. **`data/000155_SZ_full_history.csv`** - 完整数据（日线 + basic 合并）\n",
    "2. **`data/000155_SZ_daily.csv`** - 仅日线数据\n",
    "3. **`data/000155_SZ_basic.csv`** - 仅 basic 数据\n",
    "\n",
    "### 主要字段说明\n",
    "\n",
    "#### 日线数据字段：\n",
    "- `ts_code`: 股票代码\n",
    "- `trade_date`: 交易日期\n",
    "- `open`: 开盘价\n",
    "- `high`: 最高价\n",
    "- `low`: 最低价\n",
    "- `close`: 收盘价\n",
    "- `pre_close`: 昨收价\n",
    "- `change`: 涨跌额\n",
    "- `pct_chg`: 涨跌幅 (%)\n",
    "- `vol`: 成交量（手）\n",
    "- `amount`: 成交额（千元）\n",
    "\n",
    "#### Basic 数据字段：\n",
    "- `turnover_rate`: 换手率 (%)\n",
    "- `turnover_rate_f`: 换手率（自由流通股） (%)\n",
    "- `volume_ratio`: 量比\n",
    "- `pe`: 市盈率（总市值/净利润）\n",
    "- `pe_ttm`: 市盈率TTM\n",
    "- `pb`: 市净率（总市值/净资产）\n",
    "- `ps`: 市销率\n",
    "- `ps_ttm`: 市销率TTM\n",
    "- `dv_ratio`: 股息率 (%)\n",
    "- `dv_ttm`: 股息率TTM (%)\n",
    "- `total_share`: 总股本（万股）\n",
    "- `float_share`: 流通股本（万股）\n",
    "- `free_share`: 自由流通股本（万股）\n",
    "- `total_mv`: 总市值（万元）\n",
    "- `circ_mv`: 流通市值（万元）\n",
    "\n",
    "### 后续使用\n",
    "\n",
    "```python\n",
    "# 读取完整数据\n",
    "df = pd.read_csv('data/000155_SZ_full_history.csv')\n",
    "\n",
    "# 转换日期格式\n",
    "df['trade_date'] = pd.to_datetime(df['trade_date'])\n",
    "\n",
    "# 按日期排序\n",
    "df = df.sort_values('trade_date')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}